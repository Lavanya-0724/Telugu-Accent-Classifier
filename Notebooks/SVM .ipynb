{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn\n",
    "from __future__ import print_function\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from librosa import display,core\n",
    "from dtw import dtw\n",
    "from numpy import linalg as LA\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score,cross_validate\n",
    "from sklearn import metrics\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Waveform (a):\n",
    "\n",
    "The term \"audio waveform\" refers to the representation of an audio signal in the time domain. It is a continuous representation of the audio signal, showing how the sound pressure (amplitude) varies over time.\n",
    "In digital audio processing, the audio waveform is typically discretized or sampled at regular intervals to create a digital representation of the continuous analog audio signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Rate (s):\n",
    "\n",
    "The \"sample rate,\" denoted as s in the code, refers to the number of samples (audio measurements) taken per second during the analog-to-digital conversion of an audio signal. It is expressed in Hertz (Hz) and is a fundamental parameter in digital audio processing.\n",
    "The sample rate determines the granularity at which the continuous audio waveform is captured digitally. A higher sample rate provides more detail but requires more data storage and processing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def createTrainingData(start, end):\n",
    "    samples = []\n",
    "    telangana_dir = 'audio/Telangana'\n",
    "    coastal_dir = 'audio/Coastal'\n",
    "    rayalseema_dir = 'audio/Rayalseema'\n",
    "    \n",
    "    regions = {\n",
    "        'Telangana': telangana_dir,\n",
    "        'Coastal': coastal_dir,\n",
    "        'Rayalseema':rayalseema_dir\n",
    "    }\n",
    "\n",
    "    for region, region_dir in regions.items():\n",
    "        if region == 'Telangana':\n",
    "            file_range = range(239, 357)\n",
    "        elif region == 'Rayalseema':\n",
    "            file_range = range(116, 215)\n",
    "        elif region == 'Coastal':\n",
    "            file_range = range(1, 102)  # Assuming audio files in Coastal are named from '1.wav' to '101.wav'\n",
    "\n",
    "        for i in file_range:\n",
    "            ind = 0\n",
    "            try:\n",
    "                file_path = os.path.join(region_dir, f\"{i}.wav\")\n",
    "                a, s = librosa.load(file_path)\n",
    "            except:\n",
    "                ind = 1\n",
    "\n",
    "            if ind == 0:\n",
    "                mfcc = librosa.feature.mfcc(y=a, sr=s)\n",
    "                temp = mfcc.T[1][start:end]\n",
    "                for frame in range(10, 50):\n",
    "                    temp = np.concatenate((temp, mfcc.T[frame][start:end]))\n",
    "                samples.append([temp, region])\n",
    "    \n",
    "    print(len(samples))\n",
    "    X = [i[0] for i in samples]\n",
    "    Y = [j[1] for j in samples]\n",
    "    return X, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lavanya Tetakali\\AppData\\Local\\Temp\\ipykernel_23692\\3362901313.py:30: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  a, s = librosa.load(file_path)\n",
      "C:\\Users\\Lavanya Tetakali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n"
     ]
    }
   ],
   "source": [
    "clf4 = svm.SVC()\n",
    "data,label = createTrainingData(1,19)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def predict_svm(X, Y, Z):\n",
    "    svm = SVC()\n",
    "    svm.fit(X, Y)\n",
    "    prediction = svm.predict(Z)\n",
    "    scores = cross_val_score(svm, data, label)  # You should have 'data' and 'label' defined somewhere in your code.\n",
    "    print(scores.mean())\n",
    "    return prediction\n",
    "\n",
    "def printPrediction(prediction,actual_label):\n",
    "    print(\"1 -> Telangana, 0-> Coastal, 2-> Rayalseema\\n\")\n",
    "    for i in range(len(prediction)):\n",
    "        print(\"Actual ->\",actual_label[i],\" Prediction ->\",prediction[i])\n",
    "\n",
    "def accuracy(prediction,actual):\n",
    "    count=0\n",
    "    l=len(prediction)\n",
    "    for i in range(l):\n",
    "        if(prediction[i]==actual[i]):\n",
    "            count+=1\n",
    "    return count/l*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Telangana': 118, 'Coastal': 100, 'Rayalseema': 99})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Coastal', 91), ('Rayalseema', 91), ('Telangana', 91)]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(data,label)\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.5\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_resampled,y_resampled)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  0,  1],\n",
       "       [ 0, 29,  0],\n",
       "       [ 0,  1, 26]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the elements of the confusion matrix\n",
    "tn = conf_matrix[0, 0]  # True negatives\n",
    "fp = conf_matrix[0, 1]  # False positives\n",
    "fn = conf_matrix[1, 0]  # False negatives\n",
    "tp = conf_matrix[1, 1]  # True positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = round(tp/(tp+fp),4)\n",
    "recall = round(tp/(tp+fn),4)\n",
    "fmeasure = round(2*((precision*recall)/(precision+recall)),4)\n",
    "rej = round(tn/(tn+fp),4)\n",
    "acc = round((tn+tp)/(tn+tp+fp+fn),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(precision,recall,fmeasure,rej,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to svm_accent_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib  # Used to save and load models\n",
    "\n",
    "\n",
    "# Save the trained SVM model to a PKL file\n",
    "pkl_file = \"svm_accent_model.pkl\"  # Filename for your model\n",
    "joblib.dump(clf, pkl_file)  # Save the model\n",
    "\n",
    "print(f\"Model saved to {pkl_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Precision**: Measures how many of the positive predictions made by the model were actually correct. A precision of 1.0 means that when the model predicts a sample as belonging to a class, it is almost always correct.\n",
    "\n",
    "2. **Recall (Sensitivity)**: Measures how many of the actual positive samples were correctly identified by the model. A recall of 1.0 indicates that the model is very good at identifying positive samples.\n",
    "\n",
    "3. **F1-Score**: The harmonic mean of precision and recall. It provides a balance between precision and recall. An F1-score of 1.0 suggests a perfect balance between precision and recall.\n",
    "\n",
    "4. **Rejection Rate (rej)**: The proportion of true negatives out of the total negatives (true negatives + false positives). A rejection rate of 1.0 means that all negatives are correctly identified as negatives.\n",
    "\n",
    "5. **Overall Accuracy (acc)**: The proportion of correct classifications out of all predictions. An accuracy of 1.0 indicates that all predictions were correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing audio/Coastal\\100.wav: [Errno 2] No such file or directory: 'audio/Coastal\\\\100.wav'\n",
      "Accuracy: 87.5 %\n",
      "Predicted Accent: ['Rayalseema']\n"
     ]
    }
   ],
   "source": [
    "# Required Python Libraries\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"PySoundFile failed. Trying audioread instead.\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Feature Extraction Function\n",
    "def extract_features(audio_path, start=1, end=19):\n",
    "    a, s = librosa.load(audio_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=a, sr=s)\n",
    "    feature_vector = mfcc.T[1][start:end]  # Ensure consistent range of MFCCs\n",
    "    for frame in range(10, 50):\n",
    "        feature_vector = np.concatenate((feature_vector, mfcc.T[frame][start:end]))\n",
    "    return feature_vector\n",
    "\n",
    "# Create Training Data\n",
    "def create_training_data(start=1, end=19):\n",
    "    samples = []\n",
    "    regions = {\n",
    "        'Telangana': 'audio/Telangana',\n",
    "        'Coastal': 'audio/Coastal',\n",
    "        'Rayalseema': 'audio/Rayalseema'\n",
    "    }\n",
    "    \n",
    "    for region, region_dir in regions.items():\n",
    "        if region == 'Telangana':\n",
    "            file_range = range(239, 357)\n",
    "        elif region == 'Rayalseema':\n",
    "            file_range = range(116, 215)\n",
    "        elif region == 'Coastal':\n",
    "            file_range = range(1, 102)\n",
    "        \n",
    "        for i in file_range:\n",
    "            try:\n",
    "                file_path = os.path.join(region_dir, f\"{i}.wav\")\n",
    "                feature_vector = extract_features(file_path, start, end)\n",
    "                samples.append([feature_vector, region])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    # Split data into features and labels\n",
    "    X = [i[0] for i in samples]\n",
    "    Y = [j[1] for j in samples]\n",
    "    return X, Y\n",
    "\n",
    "# Create and Train the SVM Classifier\n",
    "data, label = create_training_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2)\n",
    "\n",
    "# Oversample the training set to avoid class imbalance\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the SVM classifier\n",
    "clf = SVC()\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Save the trained model to a PKL file\n",
    "pkl_file = \"svm_accent_model.pkl\"\n",
    "joblib.dump(clf, pkl_file)\n",
    "\n",
    "# Predict and Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute Accuracy\n",
    "def accuracy(prediction, actual):\n",
    "    return np.mean(np.array(prediction) == np.array(actual)) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy(y_pred, y_test), \"%\")\n",
    "\n",
    "# Function to Predict Accent with SVM\n",
    "def predict_accent(model, audio_file):\n",
    "    feature_vector = extract_features(audio_file)\n",
    "    prediction = model.predict([feature_vector])\n",
    "    return prediction\n",
    "\n",
    "# Test the Prediction with the Saved Model\n",
    "audio_file = \"audio/Rayalseema/117.wav\"  # Example audio file\n",
    "accent = predict_accent(clf, audio_file)\n",
    "print(\"Predicted Accent:\", accent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lavanya Tetakali\\AppData\\Local\\Temp\\ipykernel_23692\\3362901313.py:30: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  a, s = librosa.load(file_path)\n",
      "C:\\Users\\Lavanya Tetakali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n",
      "Mean Cross-Validation Score: 0.9267137096774194\n",
      "Accuracy: 95.3125\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F-Measure: 1.0\n",
      "Rejection: 1.0\n",
      "Overall Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Your existing code for data loading and oversampling\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2)\n",
    "\n",
    "# Oversample the training set using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create and train the SVM classifier\n",
    "clf = svm.SVC()\n",
    "data,label = createTrainingData(1,19)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, data, label, cv=10) # You can adjust the number of folds with the 'cv' parameter\n",
    "\n",
    "# Print the mean cross-validation score\n",
    "print(\"Mean Cross-Validation Score:\", np.mean(cv_scores))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "print(\"Accuracy:\", accuracy(y_pred, y_test))\n",
    "\n",
    "# Calculate and print other performance metrics (precision, recall, fmeasure, rejection, overall accuracy)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn = conf_matrix[0, 0]\n",
    "fp = conf_matrix[0, 1]\n",
    "fn = conf_matrix[1, 0]\n",
    "tp = conf_matrix[1, 1]\n",
    "\n",
    "precision = round(tp / (tp + fp), 4)\n",
    "recall = round(tp / (tp + fn), 4)\n",
    "fmeasure = round(2 * ((precision * recall) / (precision + recall)), 4)\n",
    "rej = round(tn / (tn + fp), 4)\n",
    "acc = round((tn + tp) / (tn + tp + fp + fn), 4)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-Measure:\", fmeasure)\n",
    "print(\"Rejection:\", rej)\n",
    "print(\"Overall Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "# Example usage:\n",
    "file_path_sample = 'audio/Telangana/240.wav'\n",
    "audio_features = extract_audio_features(file_path_sample)\n",
    "y, sr = librosa.load(file_path_sample, sr=None)  # Load audio file\n",
    "\n",
    "# Plotting pitch-related features\n",
    "plt.figure(figsize=(10, 16))\n",
    "\n",
    "# Plot speech signal waveform\n",
    "plt.subplot(5, 1, 1)\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title('Speech Signal Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Plot pitch contour\n",
    "plt.subplot(5, 1, 2)\n",
    "pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
    "pitches = [librosa.hz_to_midi(p) for p in pitches[pitches > 0]]\n",
    "times = librosa.times_like(np.array(pitches))  # Convert pitches to NumPy array\n",
    "plt.plot(times, pitches, label='Pitch (MIDI)')\n",
    "plt.title('Pitch Contour')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Pitch (MIDI)')\n",
    "\n",
    "# Plot energy\n",
    "plt.subplot(5, 1, 3)\n",
    "energy = np.cumsum(np.square(y))\n",
    "plt.plot(librosa.times_like(energy), energy)\n",
    "plt.title('Energy')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Energy')\n",
    "\n",
    "# Plot power spectral density (PSD)\n",
    "plt.subplot(5, 1, 4)\n",
    "psd = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "plt.plot(librosa.times_like(psd), psd)\n",
    "plt.title('Power Spectral Density (PSD)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('PSD')\n",
    "\n",
    "# Plot intensity\n",
    "plt.subplot(5, 1, 5)\n",
    "intensity = np.cumsum(np.abs(y))\n",
    "plt.plot(librosa.times_like(intensity), intensity)\n",
    "plt.title('Intensity')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Intensity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_audio_features(file_path, sr=22050):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "\n",
    "    # Extract pitch-related features using librosa\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
    "    pitches = np.array([librosa.hz_to_midi(p) for p in pitches[pitches > 0]])\n",
    "\n",
    "    min_pitch = np.min(pitches)\n",
    "    max_pitch = np.max(pitches)\n",
    "    pitch_range = max_pitch - min_pitch\n",
    "    avg_pitch = np.mean(pitches)\n",
    "    std_pitch = np.std(pitches)\n",
    "    mean_abs_slope_pitch = np.mean(np.abs(np.diff(pitches)))\n",
    "\n",
    "    # Extract other features\n",
    "    energy = np.sum(y**2)\n",
    "    psd = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    intensity = np.sum(np.abs(y))\n",
    "    \n",
    "    # Extract formants (F1, F2, F3)\n",
    "    formants = librosa.effects.harmonic(y)\n",
    "    f1 = formants[0]\n",
    "    f2 = formants[1]\n",
    "    f3 = formants[2] if len(formants) > 2 else None\n",
    "\n",
    "    return {\n",
    "        'Min Pitch (Hz)': librosa.midi_to_hz(min_pitch),\n",
    "        'Max Pitch (Hz)': librosa.midi_to_hz(max_pitch),\n",
    "        'Pitch Range (Hz)': pitch_range,\n",
    "        'Average Pitch (Hz)': librosa.midi_to_hz(avg_pitch),\n",
    "        'Std Dev Pitch (Hz)': librosa.midi_to_hz(std_pitch),\n",
    "        'Mean Abs Slope Pitch (Hz)': librosa.midi_to_hz(mean_abs_slope_pitch),\n",
    "        'Energy': energy,\n",
    "        'Power Spectral Density (PSD)': np.mean(psd),\n",
    "        'Intensity': intensity,\n",
    "        'F1 (Hz)': librosa.midi_to_hz(f1),\n",
    "        'F2 (Hz)': librosa.midi_to_hz(f2),\n",
    "        'F3 (Hz)': librosa.midi_to_hz(f3) if f3 is not None else None\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'audio/Telangana/245.wav'\n",
    "audio_features = extract_audio_features(file_path)\n",
    "print(audio_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_audio_features(file_path, sr=22050):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "\n",
    "    # Extract pitch-related features using librosa\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
    "    pitches = np.array([librosa.hz_to_midi(p) for p in pitches[pitches > 0]])\n",
    "\n",
    "    min_pitch = np.min(pitches)\n",
    "    max_pitch = np.max(pitches)\n",
    "    pitch_range = max_pitch - min_pitch\n",
    "    avg_pitch = np.mean(pitches)\n",
    "    std_pitch = np.std(pitches)\n",
    "    mean_abs_slope_pitch = np.mean(np.abs(np.diff(pitches)))\n",
    "\n",
    "    # Extract other features\n",
    "    energy = np.sum(y**2)\n",
    "    psd = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    intensity = np.sum(np.abs(y))\n",
    "    \n",
    "    # Extract formants (F1, F2, F3)\n",
    "    formants = librosa.effects.harmonic(y)\n",
    "    f1 = formants[0]\n",
    "    f2 = formants[1]\n",
    "    f3 = formants[2] if len(formants) > 2 else None\n",
    "\n",
    "    return {\n",
    "        'Min Pitch (Hz)': librosa.midi_to_hz(min_pitch),\n",
    "        'Max Pitch (Hz)': librosa.midi_to_hz(max_pitch),\n",
    "        'Pitch Range (Hz)': pitch_range,\n",
    "        'Average Pitch (Hz)': librosa.midi_to_hz(avg_pitch),\n",
    "        'Std Dev Pitch (Hz)': librosa.midi_to_hz(std_pitch),\n",
    "        'Mean Abs Slope Pitch (Hz)': librosa.midi_to_hz(mean_abs_slope_pitch),\n",
    "        'Energy': energy,\n",
    "        'Power Spectral Density (PSD)': np.mean(psd),\n",
    "        'Intensity': intensity,\n",
    "        'F1 (Hz)': librosa.midi_to_hz(f1),\n",
    "        'F2 (Hz)': librosa.midi_to_hz(f2),\n",
    "        'F3 (Hz)': librosa.midi_to_hz(f3) if f3 is not None else None\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'audio/Coastal/15.wav'\n",
    "audio_features = extract_audio_features(file_path)\n",
    "print(audio_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_audio_features(file_path, sr=22050):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "\n",
    "    # Extract pitch-related features using librosa\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
    "    pitches = np.array([librosa.hz_to_midi(p) for p in pitches[pitches > 0]])\n",
    "\n",
    "    min_pitch = np.min(pitches)\n",
    "    max_pitch = np.max(pitches)\n",
    "    pitch_range = max_pitch - min_pitch\n",
    "    avg_pitch = np.mean(pitches)\n",
    "    std_pitch = np.std(pitches)\n",
    "    mean_abs_slope_pitch = np.mean(np.abs(np.diff(pitches)))\n",
    "\n",
    "    # Extract other features\n",
    "    energy = np.sum(y**2)\n",
    "    psd = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    intensity = np.sum(np.abs(y))\n",
    "    \n",
    "    # Extract formants (F1, F2, F3)\n",
    "    formants = librosa.effects.harmonic(y)\n",
    "    f1 = formants[0]\n",
    "    f2 = formants[1]\n",
    "    f3 = formants[2] if len(formants) > 2 else None\n",
    "\n",
    "    return {\n",
    "        'Min Pitch (Hz)': librosa.midi_to_hz(min_pitch),\n",
    "        'Max Pitch (Hz)': librosa.midi_to_hz(max_pitch),\n",
    "        'Pitch Range (Hz)': pitch_range,\n",
    "        'Average Pitch (Hz)': librosa.midi_to_hz(avg_pitch),\n",
    "        'Std Dev Pitch (Hz)': librosa.midi_to_hz(std_pitch),\n",
    "        'Mean Abs Slope Pitch (Hz)': librosa.midi_to_hz(mean_abs_slope_pitch),\n",
    "        'Energy': energy,\n",
    "        'Power Spectral Density (PSD)': np.mean(psd),\n",
    "        'Intensity': intensity,\n",
    "        'F1 (Hz)': librosa.midi_to_hz(f1),\n",
    "        'F2 (Hz)': librosa.midi_to_hz(f2),\n",
    "        'F3 (Hz)': librosa.midi_to_hz(f3) if f3 is not None else None\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'audio/Rayalseema/125.wav'\n",
    "audio_features = extract_audio_features(file_path)\n",
    "print(audio_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
